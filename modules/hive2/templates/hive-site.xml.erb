<%#
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-%>
<% @metastores =
     eval(@nodes).select {|node| node[:roles].include? 'hive-meta'}.
       map {|node| node[:hostname]};
   @is_metastore = @metastores.include? @hostname;
   @dblist = eval(@nodes).select {|node| node[:roles].include? 'hive-db'};
   @db = (@dblist.size == 0 ? "unknown" : @dblist[0][:hostname]) +"."+ @domain;
   @hive2_servers = eval(@nodes).
      select {|node| node[:roles].include? 'hive2-server2'}.
      map{|node| node[:hostname]};
   @zookeeper_servers = eval(@nodes).
      select {|node| node[:roles].include? 'zk'}.
      map{|node| node[:hostname] + "." + @domain + ":2181"}.join(",");
   @ats_servers = eval(@nodes).
     select {|node| node[:roles].include? 'yarn-timelineserver'}.
     map{|node| node[:hostname] + "." + @domain};
   @llap_nodes = eval(@nodes).
       select {|node| node[:roles].include? 'hive2-llap'}.
       map {|node| node[:hostname] + "." + @domain}.join(",");
 -%>
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<% if @llap_nodes.length > 0 -%>
  <property>
    <name>hive.execution.mode</name>
    <value>llap</value>
  </property>

  <property>
    <name>hive.llap.execution.mode</name>
    <value>all</value>
  </property>

  <property>
    <name>hive.llap.io.enabled</name>
    <value>true</value>
  </property>

  <property> 
    <name>hive.llap.auto.allow.uber</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.llap.client.consistent.splits</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.llap.object.cache.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.llap.task.scheduler.locality.delay</name>
    <value>-1</value>
  </property>

  <property>
    <name>hive.tez.input.generate.consistent.splits</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.exec.orc.split.strategy</name>
    <value>BI</value>
  </property>

  <property>
    <name>llap.daemon.service.hosts</name>
    <value><%= @llap_nodes %></value>
  </property>

  <property>
    <name>llap.daemon.service.hosts</name>
    <value>@llap0</value>
  </property>

  <property>
    <name>hive.zookeeper.namespace</name>
    <value>llap</value>
  </property>

  <property>
    <name>hive.zookeeper.quorum</name>
    <value><%= @zookeeper_servers %></value>
  </property>
<% end -%>

<% if @security == "true" -%>
  <property>
    <name>hive.metastore.kerberos.keytab.file</name>
    <value><%= scope.lookupvar('hdfs_client::keytab_dir') %>/hive.keytab</value>
  </property>

  <property>
    <name>hive.metastore.kerberos.principal</name>
    <value>hive/_HOST@<%= @realm %></value>
  </property>

  <property>
    <name>hive.server2.authentication</name>
    <value>KERBEROS</value>
  </property>

  <property>
    <name>hive.server2.authentication.kerberos.keytab</name>
    <value><%= scope.lookupvar('hdfs_client::keytab_dir') %>/hive.keytab</value>
  </property>

  <property>
    <name>hive.server2.authentication.kerberos.principal</name>
    <value>hive/_HOST@<%= @realm %></value>
  </property>

  <property>
     <name>hive.llap.daemon.keytab.file</name>
     <value>/etc/security/hadoop/hive.keytab</value>
  </property>

  <property>
     <name>hive.llap.daemon.service.principal</name>
     <value>hive/_HOST@<%= @realm %></value>
  </property>

  <property>
    <name>hive.llap.validate.acls</name>
    <value>false</value>
  </property>

  <property>
     <name>hive.llap.zk.sm.principal</name>
     <value>hive@EXAMPLE.COM</value>
  </property>

  <property>
     <name>hive.llap.zk.sm.keytab.file</name>
     <value>/etc/security/hadoop/hive.headless.keytab</value>
  </property>

  <property>
     <name>hive.llap.zk.sm.connectionString</name>
     <value><%= @zookeeper_servers %></value>
  </property>
<% end -%>

<% if @hive2_servers.length > 0 -%>
  <property>
    <name>hive.server2.support.dynamic.service.discovery</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.server2.tez.initialize.default.sessions</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.server2.tez.default.queues</name>
    <value>default</value>
  </property>

  <property>
    <name>hive.server2.tez.sessions.per.default.queue</name>
    <value>1</value>
  </property>

  <property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.server2.zookeeper.namespace</name>
    <value>hiveserver2</value>
  </property>

  <property>
    <name>hive.zookeeper.quorum</name>
    <value><%= @zookeeper_servers %></value>
  </property>
<% end %>

<% if @ats_servers.length > 0 -%>
  <property>
    <name>hive.exec.failure.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.ATSHook</value>
  </property>

  <property>
    <name>hive.exec.post.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.ATSHook</value>
  </property>

  <property>
    <name>hive.exec.pre.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.ATSHook</value>
  </property>
<% end -%>

  <property>
    <name>datanucleus.autoStartMechanism</name>
    <value>SchemaTable</value>
  </property>

  <property>
    <name>datanucleus.autoCreateSchema</name>
    <value>false</value>
  </property>

  <property>
    <name>hadoop.clientside.fs.operations</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.auto.convert.join</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.auto.convert.join.noconditionaltask</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.auto.convert.join.noconditionaltask.size</name>
    <value><%= @client_mem.to_i * 1024 * 1024 / 3 %></value>
  </property>

  <property>
    <name>hive.auto.convert.sortmerge.join</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.auto.convert.sortmerge.join.to.mapjoin</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.cbo.enable</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.compute.query.using.stats</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.convert.join.bucket.mapjoin.tez</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.compactor.initiator.on</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.compactor.worker.threads</name>
    <value>1</value>
  </property>

  <property>
    <name>hive.enforce.sortmergebucketmapjoin</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.exec.compress.intermediate</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.exec.compress.output</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.exec.dynamic.partition</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>strict</value>
  </property>

  <property>
    <name>hive.execution.engine</name>
    <value>tez</value>
  </property>

  <property>
    <name>hive.fetch.task.conversion</name>
    <value>more</value>
  </property>

  <property>
    <name>hive.fetch.task.conversion.threshold</name>
    <value>1073741824</value>
  </property>

  <property>
    <name>hive.limit.optimize.enable</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.limit.pushdown.memory.usage</name>
    <value>0.04</value>
  </property>

  <property>
    <name>hive.map.aggr</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.map.aggr.hash.force.flush.memory.threshold</name>
    <value>0.9</value>
  </property>

  <property>
    <name>hive.map.aggr.hash.min.reduction</name>
    <value>0.5</value>
  </property>

  <property>
    <name>hive.map.aggr.hash.percentmemory</name>
    <value>0.5</value>
  </property>

  <property>
    <name>hive.mapjoin.bucket.cache.size</name>
    <value>10000</value>
  </property>

  <property>
    <name>hive.mapjoin.hybridgrace.hashtable</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.mapjoin.optimized.hashtable</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.merge.mapfiles</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.merge.mapredfiles</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.merge.size.per.task</name>
    <value>256000000</value>
  </property>

  <property>
    <name>hive.merge.smallfiles.avgsize</name>
    <value>16000000</value>
  </property>

  <property>
    <name>hive.merge.tezfiles</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.metastore.cache.pinobjtypes</name>
    <value>Table,Database,Type,FieldSchema,Order</value>
  </property>

  <property>
    <name>hive.metastore.client.socket.timeout</name>
    <value>60</value>
  </property>

  <property>
    <name>hive.metastore.execute.setugi</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.metastore.sasl.enabled</name>
    <value><%= @security %></value>
  </property>

  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/apps/hive/warehouse</value>
  </property>

  <property>
    <name>hive.optimize.bucketmapjoin</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.bucketmapjoin.sortedmerge</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.optimize.constant.propagation</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.dynamic.partition.hashjoin</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.index.filter</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.metadataonly</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.null.scan</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.reducededuplication</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.reducededuplication.min.reducer</name>
    <value>4</value>
  </property>

  <property>
    <name>hive.optimize.sort.dynamic.partition</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.orc.compute.splits.num.threads</name>
    <value>10</value>
  </property>
    
  <property>
    <name>hive.orc.splits.include.file.footer</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.prewarm.enabled</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.security.authorization.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.security.authorization.manager</name>
    <value>org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider</value>
  </property>

  <property>
    <name>hive.stats.fetch.column.stats</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.support.concurrency</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.tez.container.size</name>
    <value><%= @client_mem.to_i %></value>
  </property>

  <property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</value>
  </property>

  <property>
    <name>hive.vectorized.execution.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.vectorized.execution.mapjoin.minmax.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.vectorized.execution.mapjoin.native.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.vectorized.execution.reduce.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.vectorized.groupby.checkinterval</name>
    <value>4096</value>
  </property>

  <property>
    <name>hive.vectorized.groupby.flush.percent</name>
    <value>0.1</value>
  </property>

  <property>
    <name>hive.vectorized.groupby.maxentries</name>
    <value>100000</value>
  </property>

  <property>
    <name>tez.session.am.dag.submit.timeout.secs</name>
    <value>14400</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://<%= @db %>:3306/hive?createDatabaseIfNotExist=true</value>
  </property>
  
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>vagrant</value>
  </property>
</configuration>
